{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/pypoetry/virtualenvs/nouns-mech-interp-YeAXWnnL-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from vae_interp.sae import SAE\n",
    "from vae_interp.dataset import NpyDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from vae_interp.analysis import get_similar_features, get_activations_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./checkpoints/sae/sae_config.json\"\n",
    "weights_path = \"./checkpoints/sae/sae.pth\"\n",
    "sae = SAE.load_from_checkpoint(config_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NpyDataset(\"./vae_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimilarFeatures(k=10, top_k_indices_per_feature=tensor([[287, 415,  76,  ..., 286, 372, 351],\n",
       "        [ 88, 297, 279,  ...,  38, 503, 293],\n",
       "        [130, 489,  36,  ..., 177, 464, 394],\n",
       "        ...,\n",
       "        [363, 423, 136,  ..., 168, 267, 281],\n",
       "        [326,  30, 182,  ..., 244, 193, 386],\n",
       "        [319, 354, 234,  ..., 475, 289, 128]]), top_k_cosine_sim_per_feature=tensor([[0.3491, 0.2737, 0.2525,  ..., 0.2058, 0.2057, 0.2028],\n",
       "        [0.3528, 0.3357, 0.3184,  ..., 0.2759, 0.2707, 0.2610],\n",
       "        [0.2859, 0.2828, 0.2743,  ..., 0.2353, 0.2328, 0.2305],\n",
       "        ...,\n",
       "        [0.4083, 0.3586, 0.3488,  ..., 0.2819, 0.2682, 0.2635],\n",
       "        [0.4350, 0.4086, 0.3748,  ..., 0.3532, 0.3213, 0.3033],\n",
       "        [0.4316, 0.3546, 0.3500,  ..., 0.2843, 0.2796, 0.2766]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_features(sae, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find topk similar features for each feature\n",
    "k = 10\n",
    "num_features = len(sae.features)\n",
    "features_norm = sae.features / torch.linalg.norm(sae.features, dim=1, keepdim=True)\n",
    "features_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 1]), torch.Size([512, 11]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity = features_norm @ features_norm.T\n",
    "topk_indices = torch.topk(cosine_similarity, k=k + 1, dim=1).indices\n",
    "topk_cosine_sim = torch.topk(cosine_similarity, k=k + 1, dim=1).values\n",
    "feature_indices = torch.arange(0, num_features).view(-1, 1)\n",
    "feature_indices.shape, topk_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[287, 415,  76,  ..., 286, 372, 351],\n",
       "        [ 88, 297, 279,  ...,  38, 503, 293],\n",
       "        [130, 489,  36,  ..., 177, 464, 394],\n",
       "        ...,\n",
       "        [363, 423, 136,  ..., 168, 267, 281],\n",
       "        [326,  30, 182,  ..., 244, 193, 386],\n",
       "        [319, 354, 234,  ..., 475, 289, 128]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = topk_indices[topk_indices != feature_indices].view(num_features, k)\n",
    "topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3491, 0.2737, 0.2525,  ..., 0.2058, 0.2057, 0.2028],\n",
       "        [0.3528, 0.3357, 0.3184,  ..., 0.2759, 0.2707, 0.2610],\n",
       "        [0.2859, 0.2828, 0.2743,  ..., 0.2353, 0.2328, 0.2305],\n",
       "        ...,\n",
       "        [0.4083, 0.3586, 0.3488,  ..., 0.2819, 0.2682, 0.2635],\n",
       "        [0.4350, 0.4086, 0.3748,  ..., 0.3532, 0.3213, 0.3033],\n",
       "        [0.4316, 0.3546, 0.3500,  ..., 0.2843, 0.2796, 0.2766]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_cosine_sim[topk_indices != feature_indices].view(num_features, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [00:05<00:00, 136.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([49859, 512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find topk activations\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "sparse_embeddings = None\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    batch_sparse_embeddings = sae.encode(batch)\n",
    "    if sparse_embeddings is None:\n",
    "        sparse_embeddings = batch_sparse_embeddings\n",
    "    else:\n",
    "        sparse_embeddings = torch.cat([sparse_embeddings, batch_sparse_embeddings], dim=0)\n",
    "\n",
    "sparse_embeddings.shape # column is activation density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/195 [00:00<00:00, 279.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:01<00:00, 133.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ActivationsInfo(activations_per_feature=tensor([[0.0015, 0.0192, 0.0374,  ..., 0.0000, 0.0031, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0085, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0048, 0.0250, 0.0157,  ..., 0.0230, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), activation_density_per_feature=tensor([4.6865e+01, 0.0000e+00, 4.9936e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.7746e+01, 4.3838e+01, 4.6842e+01, 3.9062e-01, 4.3377e+01,\n",
       "        5.3908e+01, 0.0000e+00, 0.0000e+00, 4.7957e+01, 4.8824e+01, 4.0234e-01,\n",
       "        2.6461e+01, 0.0000e+00, 0.0000e+00, 3.9648e-01, 4.7590e+01, 4.6355e+01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3203e+00, 1.8496e+00, 0.0000e+00,\n",
       "        7.9297e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2285e+01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7070e-01, 4.2752e+01, 4.5094e+01,\n",
       "        8.2422e-01, 3.6523e-01, 0.0000e+00, 4.8113e+01, 3.8281e-01, 3.1105e+01,\n",
       "        4.6408e+01, 1.9805e+00, 3.2186e+01, 0.0000e+00, 8.7305e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 4.2246e+00, 0.0000e+00, 0.0000e+00, 8.3398e-01,\n",
       "        0.0000e+00, 4.2969e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1641e-01,\n",
       "        0.0000e+00, 4.8387e+01, 5.9199e+00, 3.8867e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3594e-01, 0.0000e+00, 5.0984e+01,\n",
       "        4.7783e+01, 0.0000e+00, 1.2656e+00, 0.0000e+00, 8.5938e-01, 0.0000e+00,\n",
       "        1.9936e+01, 0.0000e+00, 4.2117e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.8482e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8617e+01,\n",
       "        3.2447e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6797e+00,\n",
       "        2.7539e+00, 0.0000e+00, 4.9922e+01, 0.0000e+00, 0.0000e+00, 1.3096e+01,\n",
       "        0.0000e+00, 0.0000e+00, 7.4121e+00, 3.9844e-01, 0.0000e+00, 3.4180e-01,\n",
       "        0.0000e+00, 3.8086e-01, 3.6328e-01, 4.9787e+01, 3.6719e-01, 8.5391e+00,\n",
       "        4.9398e+01, 3.6621e+00, 4.9016e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.3555e+00, 0.0000e+00, 5.0848e+01, 0.0000e+00, 0.0000e+00, 4.9109e+01,\n",
       "        0.0000e+00, 4.2773e-01, 0.0000e+00, 4.6289e-01, 0.0000e+00, 0.0000e+00,\n",
       "        3.7695e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7891e+00,\n",
       "        0.0000e+00, 8.6523e-01, 7.9883e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.0625e-01, 0.0000e+00, 3.7500e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8082e+01, 4.7936e+01, 0.0000e+00,\n",
       "        0.0000e+00, 5.0559e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8281e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 6.9414e+00, 7.5586e-01, 5.3105e+00, 0.0000e+00, 4.1949e+01,\n",
       "        0.0000e+00, 0.0000e+00, 4.6422e+01, 1.1299e+01, 1.2758e+01, 4.0430e-01,\n",
       "        3.4248e+01, 3.8672e-01, 1.1896e+01, 0.0000e+00, 4.8410e+01, 4.1797e-01,\n",
       "        4.2383e-01, 4.2971e+01, 3.3338e+01, 0.0000e+00, 0.0000e+00, 2.4023e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8574e+00,\n",
       "        4.8354e+01, 0.0000e+00, 4.6709e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9648e+00, 4.4016e+01,\n",
       "        0.0000e+00, 8.0078e-01, 0.0000e+00, 0.0000e+00, 4.1594e+01, 0.0000e+00,\n",
       "        4.5830e+01, 0.0000e+00, 0.0000e+00, 4.3975e+01, 0.0000e+00, 0.0000e+00,\n",
       "        1.8934e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        8.3789e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0625e-01, 0.0000e+00,\n",
       "        4.7361e+01, 0.0000e+00, 0.0000e+00, 4.6557e+01, 4.8924e+01, 8.4961e-01,\n",
       "        0.0000e+00, 4.9193e+01, 0.0000e+00, 0.0000e+00, 3.8672e-01, 4.2666e+01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5215e+00, 7.8125e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.8281e+00, 0.0000e+00, 7.2070e-01, 8.0469e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7930e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.1211e-01, 0.0000e+00, 4.8996e+01, 4.4727e-01, 0.0000e+00, 0.0000e+00,\n",
       "        1.1250e+00, 3.4195e+01, 0.0000e+00, 2.6031e+01, 4.7916e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.4609e-01, 4.9797e+01, 4.8623e+01,\n",
       "        2.4729e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3074e+01, 4.6680e-01,\n",
       "        4.9389e+01, 2.3438e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0176e+00,\n",
       "        0.0000e+00, 0.0000e+00, 4.5117e-01, 4.0430e-01, 0.0000e+00, 0.0000e+00,\n",
       "        3.1193e+01, 3.9648e-01, 0.0000e+00, 0.0000e+00, 8.3008e-01, 2.4057e+01,\n",
       "        8.2617e-01, 0.0000e+00, 4.2188e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.9180e+00, 0.0000e+00, 0.0000e+00, 1.9531e-03, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.9961e+00, 3.3789e-01, 3.5309e+01, 0.0000e+00,\n",
       "        4.0820e-01, 3.8867e-01, 0.0000e+00, 2.4018e+01, 0.0000e+00, 4.4250e+01,\n",
       "        8.5938e-01, 0.0000e+00, 3.1203e+01, 0.0000e+00, 1.2188e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 5.0533e+01, 0.0000e+00, 4.7119e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.7891e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 5.0176e+00, 8.3008e-01, 8.7305e-01, 0.0000e+00, 4.7473e+01,\n",
       "        0.0000e+00, 0.0000e+00, 8.2812e-01, 2.3734e+01, 4.6635e+01, 0.0000e+00,\n",
       "        1.9197e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4508e+01, 4.9758e+01,\n",
       "        0.0000e+00, 2.4023e+00, 5.6992e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 8.3398e-01, 0.0000e+00, 3.8477e-01, 0.0000e+00, 3.7695e-01,\n",
       "        2.0801e+00, 0.0000e+00, 3.4262e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        3.9361e+01, 4.0820e-01, 3.8086e-01, 4.8785e+01, 0.0000e+00, 4.7139e+01,\n",
       "        0.0000e+00, 7.6562e-01, 0.0000e+00, 0.0000e+00, 1.1855e+00, 3.7109e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7715e+01, 0.0000e+00, 0.0000e+00,\n",
       "        3.6133e-01, 1.1953e+00, 0.0000e+00, 0.0000e+00, 2.0365e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 4.6277e+01, 3.3008e-01, 0.0000e+00, 4.6115e+01,\n",
       "        3.9377e+01, 4.7938e+01, 1.9980e+00, 0.0000e+00, 0.0000e+00, 4.1797e-01,\n",
       "        0.0000e+00, 0.0000e+00, 1.5516e+01, 0.0000e+00, 4.6002e+01, 0.0000e+00,\n",
       "        1.3516e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4141e+01,\n",
       "        1.9811e+01, 4.2578e-01, 0.0000e+00, 0.0000e+00, 7.5625e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.3359e+00, 7.9688e-01, 4.8373e+01, 0.0000e+00, 4.7471e+01,\n",
       "        3.9949e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6424e+01, 0.0000e+00,\n",
       "        3.7891e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3203e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.1973e+00, 4.4834e+01, 5.1727e+01, 4.1406e-01,\n",
       "        0.0000e+00, 1.0381e+01, 4.2445e+01, 1.2148e+00, 1.6094e+00, 1.6582e+00,\n",
       "        0.0000e+00, 0.0000e+00, 3.2988e+00, 0.0000e+00, 4.6561e+01, 1.9531e-03,\n",
       "        1.9531e-03, 0.0000e+00, 0.0000e+00, 4.1406e-01, 5.0660e+01, 4.0039e-01,\n",
       "        3.4891e+01, 0.0000e+00, 3.9844e-01, 0.0000e+00, 1.1816e+00, 4.7543e+01,\n",
       "        4.5281e+01, 0.0000e+00, 4.0135e+01, 0.0000e+00, 4.2188e-01, 4.9863e+01,\n",
       "        7.5977e-01, 0.0000e+00]), top_k_indices_per_feature=tensor([[48420, 33544, 35132,  ..., 20624, 25157, 28473],\n",
       "        [    8,     9,     4,  ...,     0,     2,     6],\n",
       "        [48574,  4154, 11509,  ..., 20761, 25910, 34579],\n",
       "        ...,\n",
       "        [22193, 48899, 26709,  ..., 39472, 28567, 30877],\n",
       "        [41366, 27084, 28054,  ...,   905,  2134, 31511],\n",
       "        [    8,     9,     4,  ...,     0,     2,     6]]), top_k_activations_per_feature=tensor([[0.0772, 0.0654, 0.0621,  ..., 0.0582, 0.0579, 0.0575],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0511, 0.0497, 0.0486,  ..., 0.0462, 0.0460, 0.0454],\n",
       "        ...,\n",
       "        [0.0491, 0.0474, 0.0456,  ..., 0.0426, 0.0424, 0.0423],\n",
       "        [0.0641, 0.0611, 0.0608,  ..., 0.0601, 0.0601, 0.0600],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_activations_info(sae, dataset, batch_size=256, top_k=10, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows = sparse embedding of an image feature, cols i = activations for feature i\n",
    "\n",
    "topk_image_activations = torch.topk(sparse_embeddings, k=k, dim=0).indices\n",
    "topk_image_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0772, 0.0000, 0.0511,  ..., 0.0491, 0.0641, 0.0000],\n",
       "        [0.0654, 0.0000, 0.0497,  ..., 0.0474, 0.0611, 0.0000],\n",
       "        [0.0621, 0.0000, 0.0486,  ..., 0.0456, 0.0608, 0.0000],\n",
       "        ...,\n",
       "        [0.0582, 0.0000, 0.0462,  ..., 0.0426, 0.0601, 0.0000],\n",
       "        [0.0579, 0.0000, 0.0460,  ..., 0.0424, 0.0601, 0.0000],\n",
       "        [0.0575, 0.0000, 0.0454,  ..., 0.0423, 0.0600, 0.0000]],\n",
       "       grad_fn=<TopkBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_image_activations = torch.topk(sparse_embeddings, k=k, dim=0).values\n",
    "topk_image_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.8126e-01, 0.0000e+00, 5.1279e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.9030e-01, 4.5017e-01, 4.8102e-01, 4.0113e-03, 4.4544e-01,\n",
       "        5.5358e-01, 0.0000e+00, 0.0000e+00, 4.9247e-01, 5.0137e-01, 4.1317e-03,\n",
       "        2.7173e-01, 0.0000e+00, 0.0000e+00, 4.0715e-03, 4.8870e-01, 4.7602e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4634e-02, 1.8994e-02, 0.0000e+00,\n",
       "        8.1430e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3422e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8336e-03, 4.3902e-01, 4.6307e-01,\n",
       "        8.4639e-03, 3.7506e-03, 0.0000e+00, 4.9407e-01, 3.9311e-03, 3.1942e-01,\n",
       "        4.7656e-01, 2.0337e-02, 3.3051e-01, 0.0000e+00, 8.9653e-03, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 4.3382e-02, 0.0000e+00, 0.0000e+00, 8.5642e-03,\n",
       "        0.0000e+00, 4.4124e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3836e-03,\n",
       "        0.0000e+00, 4.9688e-01, 6.0791e-02, 3.9913e-03, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5842e-03, 0.0000e+00, 5.2356e-01,\n",
       "        4.9068e-01, 0.0000e+00, 1.2997e-02, 0.0000e+00, 8.8249e-03, 0.0000e+00,\n",
       "        2.0472e-01, 0.0000e+00, 4.3250e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.9786e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9925e-01,\n",
       "        3.3320e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7518e-02,\n",
       "        2.8280e-02, 0.0000e+00, 5.1265e-01, 0.0000e+00, 0.0000e+00, 1.3448e-01,\n",
       "        0.0000e+00, 0.0000e+00, 7.6115e-02, 4.0915e-03, 0.0000e+00, 3.5099e-03,\n",
       "        0.0000e+00, 3.9110e-03, 3.7305e-03, 5.1126e-01, 3.7706e-03, 8.7687e-02,\n",
       "        5.0727e-01, 3.7606e-02, 5.0334e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.3919e-02, 0.0000e+00, 5.2215e-01, 0.0000e+00, 0.0000e+00, 5.0430e-01,\n",
       "        0.0000e+00, 4.3924e-03, 0.0000e+00, 4.7534e-03, 0.0000e+00, 0.0000e+00,\n",
       "        3.8709e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8641e-02,\n",
       "        0.0000e+00, 8.8851e-03, 8.2031e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.1718e-03, 0.0000e+00, 3.8509e-03, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9375e-01, 4.9225e-01, 0.0000e+00,\n",
       "        0.0000e+00, 5.1918e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0118e-02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 7.1281e-02, 7.7619e-03, 5.4534e-02, 0.0000e+00, 4.3077e-01,\n",
       "        0.0000e+00, 0.0000e+00, 4.7670e-01, 1.1603e-01, 1.3101e-01, 4.1517e-03,\n",
       "        3.5169e-01, 3.9712e-03, 1.2216e-01, 0.0000e+00, 4.9712e-01, 4.2921e-03,\n",
       "        4.3523e-03, 4.4126e-01, 3.4235e-01, 0.0000e+00, 0.0000e+00, 2.4670e-02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9343e-02,\n",
       "        4.9654e-01, 0.0000e+00, 4.7965e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0446e-02, 4.5199e-01,\n",
       "        0.0000e+00, 8.2232e-03, 0.0000e+00, 0.0000e+00, 4.2712e-01, 0.0000e+00,\n",
       "        4.7063e-01, 0.0000e+00, 0.0000e+00, 4.5157e-01, 0.0000e+00, 0.0000e+00,\n",
       "        1.9443e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        8.6043e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1718e-03, 0.0000e+00,\n",
       "        4.8635e-01, 0.0000e+00, 0.0000e+00, 4.7809e-01, 5.0240e-01, 8.7246e-03,\n",
       "        0.0000e+00, 5.0516e-01, 0.0000e+00, 0.0000e+00, 3.9712e-03, 4.3814e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7238e-02, 8.0226e-03, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.9042e-02, 0.0000e+00, 7.4009e-03, 8.2633e-03,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9757e-02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.2319e-03, 0.0000e+00, 5.0314e-01, 4.5930e-03, 0.0000e+00, 0.0000e+00,\n",
       "        1.1553e-02, 3.5115e-01, 0.0000e+00, 2.6731e-01, 4.9205e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6616e-03, 5.1136e-01, 4.9931e-01,\n",
       "        2.5394e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3426e-01, 4.7935e-03,\n",
       "        5.0717e-01, 2.4068e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0718e-02,\n",
       "        0.0000e+00, 0.0000e+00, 4.6331e-03, 4.1517e-03, 0.0000e+00, 0.0000e+00,\n",
       "        3.2032e-01, 4.0715e-03, 0.0000e+00, 0.0000e+00, 8.5240e-03, 2.4704e-01,\n",
       "        8.4839e-03, 0.0000e+00, 4.3322e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.9696e-02, 0.0000e+00, 0.0000e+00, 2.0057e-05, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.0498e-02, 3.4698e-03, 3.6258e-01, 0.0000e+00,\n",
       "        4.1918e-03, 3.9913e-03, 0.0000e+00, 2.4664e-01, 0.0000e+00, 4.5440e-01,\n",
       "        8.8249e-03, 0.0000e+00, 3.2042e-01, 0.0000e+00, 1.2515e-02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 5.1892e-01, 0.0000e+00, 4.8386e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.8641e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 5.1525e-02, 8.5240e-03, 8.9653e-03, 0.0000e+00, 4.8749e-01,\n",
       "        0.0000e+00, 0.0000e+00, 8.5040e-03, 2.4373e-01, 4.7889e-01, 0.0000e+00,\n",
       "        1.9714e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4898e-01, 5.1096e-01,\n",
       "        0.0000e+00, 2.4670e-02, 5.8525e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 8.5642e-03, 0.0000e+00, 3.9511e-03, 0.0000e+00, 3.8709e-03,\n",
       "        2.1360e-02, 0.0000e+00, 3.5183e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.0420e-01, 4.1918e-03, 3.9110e-03, 5.0097e-01, 0.0000e+00, 4.8407e-01,\n",
       "        0.0000e+00, 7.8622e-03, 0.0000e+00, 0.0000e+00, 1.2174e-02, 3.8107e-03,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8998e-01, 0.0000e+00, 0.0000e+00,\n",
       "        3.7105e-03, 1.2275e-02, 0.0000e+00, 0.0000e+00, 2.0913e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 4.7522e-01, 3.3896e-03, 0.0000e+00, 4.7356e-01,\n",
       "        4.0436e-01, 4.9227e-01, 2.0518e-02, 0.0000e+00, 0.0000e+00, 4.2921e-03,\n",
       "        0.0000e+00, 0.0000e+00, 1.5933e-01, 0.0000e+00, 4.7239e-01, 0.0000e+00,\n",
       "        1.3879e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4790e-01,\n",
       "        2.0343e-01, 4.3723e-03, 0.0000e+00, 0.0000e+00, 7.7659e-02, 0.0000e+00,\n",
       "        0.0000e+00, 4.4526e-02, 8.1831e-03, 4.9674e-01, 0.0000e+00, 4.8747e-01,\n",
       "        4.1024e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7672e-01, 0.0000e+00,\n",
       "        3.8910e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5441e-03, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 1.2295e-02, 4.6040e-01, 5.3118e-01, 4.2520e-03,\n",
       "        0.0000e+00, 1.0660e-01, 4.3587e-01, 1.2475e-02, 1.6527e-02, 1.7028e-02,\n",
       "        0.0000e+00, 0.0000e+00, 3.3876e-02, 0.0000e+00, 4.7813e-01, 2.0057e-05,\n",
       "        2.0057e-05, 0.0000e+00, 0.0000e+00, 4.2520e-03, 5.2023e-01, 4.1116e-03,\n",
       "        3.5829e-01, 0.0000e+00, 4.0915e-03, 0.0000e+00, 1.2134e-02, 4.8822e-01,\n",
       "        4.6499e-01, 0.0000e+00, 4.1214e-01, 0.0000e+00, 4.3322e-03, 5.1204e-01,\n",
       "        7.8020e-03, 0.0000e+00])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_embeddings = (sparse_embeddings != 0).float()\n",
    "total_activations = binary_embeddings.sum(dim=0)\n",
    "activation_densities = total_activations / binary_embeddings.shape[0]\n",
    "activation_densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_densities[activation_densities == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nouns-mech-interp-YeAXWnnL-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
